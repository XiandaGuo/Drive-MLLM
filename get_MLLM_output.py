import json
import time
import logging
from PIL import Image
from datasets import load_dataset
from api_clients import get_openai_output, get_gemini_output
import argparse

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def get_mllm_output_with_retry(
        pil_image: Image.Image,
        input_prompt: str,
        api_type: str,
        max_retries: int = 3,
        delay: int = 3
) -> str:
    """
    Attempts to retrieve the MLLM output with retry mechanism.

    Parameters:
    pil_image (Image.Image): The image to be processed.
    input_prompt (str): The input prompt to be sent with the image.
    api_type (str): The type of API to use for processing.
    max_retries (int, optional): Maximum number of retry attempts. Defaults to 3.
    delay (int, optional): Time in seconds to wait between retries. Defaults to 3.

    Returns:
    str: The output from the MLLM API if the call is successful.

    Raises:
    Exception: If the maximum number of retries is reached without success.
    """
    retries = 0
    while retries < max_retries:
        try:
            output_data: str = get_mllm_output(pil_image, input_prompt, api_type)
            return output_data
        except Exception as e:
            logger.error(f"Error calling get_mllm_output: {e}. Retrying {retries + 1}/{max_retries}...")
            retries += 1
            time.sleep(delay)

    raise Exception(f"Failed to get MLLM output after {max_retries} retries.")


def get_mllm_output(pil_image: Image.Image, input_prompt: str, api_type: str) -> str:
    """
    Retrieves output from the specified MLLM (Machine Learning Language Model) API
    based on the provided image and prompt.

    Parameters:
    pil_image (PIL.Image.Image): The image to be processed and sent to the MLLM API.
    input_prompt (str): The text prompt to be sent along with the image.
    api_type (str): The type of API to use ("openai" or "gemini").

    Returns:
    str: The response generated by the selected API.

    Raises:
    ValueError: If the specified API type is not supported.
    """
    # Call the appropriate function based on the API type
    if api_type == "openai":
        return get_openai_output(pil_image, input_prompt, model="gpt-4o")
    elif api_type == "gemini":
        return get_gemini_output(pil_image, input_prompt, model="models/gemini-1.5-flash")
    else:
        raise ValueError(f"API type '{api_type}' is not supported. Supported types are 'openai' and 'gemini'.")


def main(config):
    api_type = config.api_type
    prompt_file = config.prompt_file
    hf_dataset = config.hf_dataset
    save_json_file = f"./mllm_output_{api_type}.json"

    # Load prompt
    logger.info(f"{'=' * 30} Loading Eval Prompt {'=' * 30}")
    object_type = "vehicle"
    with open(prompt_file) as f:
        eval_prompt = (f.read()).format(object_type)
    prompt = eval_prompt
    logger.info(f"Prompt: {eval_prompt}")

    # Load dataset
    logger.info(f"{'=' * 30} Loading Dataset {'=' * 30}")
    logger.info("This may take a while.")
    dataset = load_dataset(hf_dataset, split='validation')
    dataset_num = len(dataset)  # len(dataset)
    logger.info(f"Loaded {dataset_num} data from the dataset.")

    # Get MLLM output for each image
    logger.info(f"{'=' * 30} Generating MLLM Output {'=' * 30}")
    mllm_outputs = []
    for data_index in range(dataset_num):
        logger.info(f"Processing image {data_index}...")
        image = dataset[data_index]['image']

        try:
            mllm_output = get_mllm_output_with_retry(image, prompt, api_type, max_retries=10)
            logger.info(f"Output: {mllm_output}")
            mllm_outputs.append(dict(pic_index=data_index, output=mllm_output))
        except Exception as e:
            logger.error(f"Failed to process image {data_index}: {e}")

    # Save MLLM outputs to JSON file
    logger.info(f"{'=' * 30} Saving Output to File {'=' * 30}")
    with open(save_json_file, 'w') as json_file:
        json.dump(mllm_outputs, json_file, indent=4)
    logger.info(f"MLLM output saved to {save_json_file}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Process some integers.")
    parser.add_argument('--api_type', type=str, default='gemini',
                        help='API type (default: gemini)')
    parser.add_argument('--prompt_file', type=str, default='./eval_prompt.txt',
                        help='File path for evaluation prompt (default: ./eval_prompt.txt)')
    parser.add_argument('--hf_dataset', type=str, default='bonbon-rj/MLLM_eval_dataset',
                        help='Hugging Face dataset path (default: bonbon-rj/MLLM_eval_dataset)')

    args = parser.parse_args()
    main(args)
